{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOAR with SIMsalabim\n",
    "Version 0.1\n",
    "(c) Larry Lueer, Vincent M. Le Corre, i-MEET 2021-2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is made to use BOAR in combination with drift-diffusion modeling to fit of 'fake' JV curves.\\\n",
    "To perform the drift-diffusion simulation in the background we use the open-source program [SIMsalabim](https://github.com/kostergroup/SIMsalabim), for more information about SIMsalabim please check the [GitHub repository](https://github.com/kostergroup/SIMsalabim) \\\n",
    "\n",
    "Here we are fitting some 'fake' data that are generated by the drift-diffusion model.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate matplotlib widgets\n",
    "%matplotlib inline\n",
    "# comment the next line if you are on the jupyterhub server\n",
    "%matplotlib widget \n",
    "# %matplotlib notebook\n",
    "\n",
    "# Import libraries\n",
    "import sys\n",
    "from numpy.random import default_rng\n",
    "from scipy import interpolate\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # comment this out to see warnings\n",
    "\n",
    "# Import boar\n",
    "# import one folder up\n",
    "sys.path.append('../') # comment out if the Notebook is in the Notebooks folder\n",
    "from boar import *\n",
    "# Import homemade package by VLC\n",
    "# import boar.SIMsalabim_utils.plot_settings_screen # to set default plot settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to SIMsalabim\n",
    "path2simu = os.path.join('/home/vlc/Desktop/' , 'SIMsalabim','SimSS') # path to the SIMsalabim directory\n",
    "# Directory where the results are stored\n",
    "curr_dir = os.getcwd()\n",
    "res_dir = os.path.join(curr_dir,'temp') # path to the results directory, use this line if Notebook is in the Notebooks folder\n",
    "# res_dir = os.path.join('../','temp') # path to the results directory, use this line if Notebook is in the Notebooks folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Fitparameters\n",
    "True_params = {'kdirect':5e-18,'mun_0':2e-8,'mup_0':8e-8,'Nc':5e26,'Gehp':1.28e28,'W_L':0}#,'Rseries':3e-4,'Bulk_tr':1e20,'Gehp':1.28e28}\n",
    "params = []\n",
    "\n",
    "kdirect = Fitparam(name = 'kdirect', val = True_params['kdirect'] , relRange = 1.5, lims=[1e-18,1e-16],range_type='log',optim_type='log',display_name='k$_{2}$ [m$^{3}$ s$^{-1}$]') \n",
    "params.append(kdirect)\n",
    "kdirect.startVal = 2e-18\n",
    "mun_0 = Fitparam(name = 'mun_0', val = True_params['mun_0'] , relRange = 1.5, lims=[1e-8,1e-7],range_type='log',optim_type='log',display_name='$\\mu_n$ [m$^{2}$ V$^{-1}$ s$^{-1}$]')\n",
    "params.append(mun_0)\n",
    "mun_0.startVal = 4e-8\n",
    "mup_0 = Fitparam(name = 'mup_0', val = True_params['mup_0'] , relRange = 1.5, lims=[1e-8,1e-7],range_type='log',optim_type='log',display_name='$\\mu_p$ [m$^{2}$ V$^{-1}$ s$^{-1}$]')\n",
    "params.append(mup_0)\n",
    "mup_0.startVal = 4e-8\n",
    "# Nc = Fitparam(name = 'Nc', val = True_params['Nc'] , relRange = 1.5, lims=[1e26,1e27],range_type='log',optim_type='log',lim_type='absolute',axis_type='log',display_name='N$_{c}$ [m$^{-3}]$')\n",
    "# params.append(Nc)\n",
    "# Nc.startVal = 5e26\n",
    "# W_L = Fitparam(name = 'W_L', val = True_params['W_L'] , relRange = 1.5, lims=[0,0.2],range_type='linear',optim_type='linear',lim_type='absolute',display_name='W$_{L}$ [eV]')\n",
    "# params.append(W_L)\n",
    "\n",
    "params_true = copy.deepcopy(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define figures-of-merit (FOMs)\n",
    "FOMs = []\n",
    "FOMs.append(FOMparam(Theta_B, name = 'Theta_B', display_name='$\\\\theta_B$', optim_type = 'log'))\n",
    "FOMs.append(FOMparam(delta_B, name = 'delta_B', display_name='$\\delta_B$', optim_type = 'log'))\n",
    "\n",
    "\n",
    "FOM_names = [fom.display_name for fom in FOMs] # names of the FOMs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare fake data for fitting\n",
    "In the next block we create some fake data with some random noise and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create some fake data\n",
    "Nc = 1 # number of fake datasets\n",
    "V = np.linspace(0,1,100) # voltage\n",
    "Gfrac = np.asarray([0.01,0.5,1]) # Gfrac, i.e. light intensity\n",
    "\n",
    "X_dimensions = ['Vext','Gfrac'] # dimensions of the X array\n",
    "X = np.array([[x,y] for y in Gfrac for x in V ] ) # X array\n",
    "Xplot = Gfrac # X array for plotting\n",
    "\n",
    "# Generate the fake data to fit\n",
    "degradation_run = True\n",
    "True_paramsList = []\n",
    "\n",
    "# define the degradation of kdirect\n",
    "kvals = np.geomspace(5e-18,5e-17,Nc) # simulate degradation of kdirect\n",
    "\n",
    "dda = Drift_diffusion_agent(path2simu=path2simu) # instantiate the agent\n",
    "\n",
    "ys = []\n",
    "True_vals = []\n",
    "True_FOMs = []\n",
    "for kval in kvals:\n",
    "    kdirect.val = kval\n",
    "    True_paramsList.append({'kdirect':kval})\n",
    "    True_params['kdirect'] = kval\n",
    "    # store the true values for plotting later\n",
    "    True_vals.append(True_params.copy())\n",
    "    FOM_dum = dda.get_FOM({'kdirect':kval,'mun_0':True_params['mun_0'],'mup_0':True_params['mup_0'],'Nc':True_params['Nc'],'Gehp':True_params['Gehp']}, FOMs) ##,'Nc':True_params['Nc']}\n",
    "    idx = 0\n",
    "    for fom,val in zip(FOMs,FOM_dum):\n",
    "        if fom.optim_type=='log':\n",
    "            FOM_dum[fom.name] = 10**FOM_dum[fom.name]\n",
    "        else:\n",
    "            FOM_dum[fom.name] = FOM_dum[fom.name]*fom.p0m\n",
    "    True_FOMs.append(copy.deepcopy(FOM_dum))\n",
    "\n",
    "    y = dda.DriftDiffusion_relative(X,params,X_dimensions=X_dimensions, max_jobs=3)\n",
    "    rng = default_rng()#\n",
    "    noise = rng.standard_normal(y.shape) * 1.9\n",
    "    #noise = noise * X[:,1] # try this: higher T - higher noise  \n",
    "    y+=noise # add some noise\n",
    "    ys.append(y)\n",
    "  \n",
    "    plt.plot(X[:,0],y,'o')\n",
    "plt.xlabel('Vext [V]')\n",
    "plt.ylabel('Current Density [A/m$^2$]')\n",
    "# save params list to be modified later to store true values\n",
    "params_true = copy.deepcopy(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the datasets one by one\n",
    "pf,pf_fom = [],[]\n",
    "mo = MultiObjectiveOptimizer(params=params,res_dir=res_dir)\n",
    "\n",
    "n_jobs = 4 # was 4\n",
    "n_jobs_init = 25 # was 4\n",
    "n_yscale=20 # was 20\n",
    "n_BO = 60 # was 60\n",
    "n_initial_points = 60 # was 200\n",
    "n_BO_warmstart = 60 # was 5\n",
    "\n",
    "for ii,y in enumerate(ys):\n",
    "    target = {'model':partial(dda.DriftDiffusion_relative,X_dimensions=X_dimensions,max_jobs=3),'target_name':'JV','data':{'X':X,'y':y,\n",
    "                'X_dimensions':['Vext','Gfrac'],'X_units':['V','sun'],'y_dimension':'Current density','y_unit':r'$A/mÂ²$'},'weight':1,'target_weight':1}\n",
    "    mo.targets = [target]\n",
    "    mo.params = params\n",
    "    mo.warmstart = 'collect_init' if ii==0 else 'recall'\n",
    "    # mo.warmstart = 'None'\n",
    "    mo.SaveOldXY2file = os.path.join(res_dir,'old_XY.json') # path to the file where old points are saved\n",
    "    mo.Path2OldXY = os.path.join(res_dir,'old_XY.json') # path to the file where old points are saved\n",
    "   \n",
    "    kwargs = {'check_improvement':'relax','max_loop_no_improvement':10,'xtol':1e-3,'ftol':1e-3}\n",
    "    kwargs_posterior = {'Nres':10,'gaussfilt':3,'logscale':True,'vmin':1e-100,'zoom':0,'min_prob':1e-40,'clear_axis':False,'True_values':True_vals[ii],'show_points':True,'savefig':False,'figname':'param_posterior'+str(ii)}\n",
    "    kwargs_plot_obj = {'zscale':'linear'}\n",
    "\n",
    "    r = mo.optimize_sko_parallel(n_jobs=n_jobs,n_yscale=n_yscale, n_BO=n_BO, n_initial_points = n_initial_points,n_BO_warmstart=n_BO_warmstart,n_jobs_init=n_jobs_init,kwargs=kwargs,verbose=False,loss='linear',threshold=1000,base_estimator = 'GP',show_objective_func=False,show_posterior=True,kwargs_posterior = kwargs_posterior,kwargs_plot_obj=kwargs_plot_obj)\n",
    "    pf.append(deepcopy(mo.params)) # collects optimized fitparameters\n",
    "    rrr = r['r'] # the results dict of the last optimizer.tell()\n",
    "\n",
    "    FOM_list = dda.get_FOMs(rrr.x_iters,params,FOMs)\n",
    "    \n",
    "    for idx,fom in enumerate(FOMs): # update the FOMs with the optimized values\n",
    "        fom.update_FOMparam(FOM_list[:,idx])\n",
    "    \n",
    "\n",
    "    kwargs_plot_obj = {'zscale':'linear'}\n",
    "    kwargs_posterior = {'Nres':5,'gaussfilt':3,'logscale':True,'vmin':1e-100,'zoom':0,'min_prob':1e-40,'clear_axis':True,'show_points':True,'True_values':True_FOMs[ii],'savefig':False,'figname':'FOM_posterior'+str(ii)}\n",
    "    FOM_min,FOM_std = mo.single_point(FOM_list.tolist(),list(rrr.func_vals),FOMs,n_jobs=4,base_estimator='GP',n_initial_points = 50,show_objective_func=False,kwargs_plot_obj=kwargs_plot_obj,show_posterior=True,kwargs_posterior = kwargs_posterior)\n",
    "    for i in range(len(FOMs)):\n",
    "        if FOMs[i].optim_type=='log':\n",
    "            FOMs[i].val = 10**FOM_min[i]  \n",
    "        else:\n",
    "            FOMs[i].val = FOM_min[i]\n",
    "        FOMs[i].std = FOM_std[i]\n",
    "\n",
    "    pf_fom.append(deepcopy(FOMs)) # collects optimized FOMs\n",
    "\n",
    "    #get true parameters and make a params object\n",
    "    for param in params_true:\n",
    "        if param.name in True_paramsList[ii]:\n",
    "            param.val = True_paramsList[ii][param.name]\n",
    "\n",
    "    # plot the fit results\n",
    "    fit_results = []\n",
    "    kwargs_plot_res = {'x_scaling':1,'xaxis_label':'Voltage [V]','xscale_type':'linear','y_scaling':10,'yaxis_label':'Current density [mA cm$^2$]','yscale_type':'linear','norm_data':False,'delog':False,'figsize':(10,10),'savefig':False,'figname':'JV_fits_' + str(ii),'figdir':'temp'}\n",
    "\n",
    "    for num,t in enumerate(mo.targets):\n",
    "        kwargs_plot_res['figname'] = os.path.join(res_dir,t['target_name']+f'_fit_{num}')\n",
    "        dda.plot_fit_res(t,mo.params,'Vext',xlim=[],ylim=[],kwargs=kwargs_plot_res)\n",
    "\n",
    "        X = t['data']['X']\n",
    "        y = t['data']['y']\n",
    "        X_dimensions = t['data']['X_dimensions']\n",
    "        yfit = t['model'](X,params,X_dimensions=X_dimensions) # get the best fits\n",
    "\n",
    "        data = np.concatenate((X, y.reshape(len(y),1), yfit.reshape(len(yfit),1)), axis=1)\n",
    "        fit_results.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the parameters evolution\n",
    "param_plot = dda.plot_params(pf,kwargs={'savefig':True,'figname':'plot_param','figdir':'temp','nrows':2,'ncols':3,'figsize':(10,10)})\n",
    "fom_plot = dda.plot_params(pf_fom,kwargs={'savefig':True,'figname':'plot_FOM','figdir':'temp','nrows':1,'ncols':2,'figsize':(10,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean output files from simulation folders\n",
    "from boar.SIMsalabim_utils.CleanFolder import *\n",
    "# path2simu = '/home/vlc/Desktop/PVLC_notebook/Simulation_program/SIMsalabimv433/SimSS'\n",
    "Do_Cleaning = True # Careful, this will delete all files in the folder\n",
    "if Do_Cleaning:\n",
    "    clean_up_output('tj',path2simu)\n",
    "    clean_up_output('tVG',path2simu)\n",
    "    clean_up_output('JV',path2simu)\n",
    "    clean_up_output('Var',path2simu)\n",
    "    clean_up_output('scPars',path2simu)\n",
    "    clean_up_output('Str4Parallel',path2simu)\n",
    "    # os.remove(mo.path2oldxy) # remove the old_xy.json file if it exists\n",
    "    # delete warmstart folder if it exists\n",
    "    if os.path.exists(os.path.join(os.getcwd(),'warmstart/')):\n",
    "        shutil.rmtree(os.path.join(os.getcwd(),'warmstart/'))\n",
    "    # delete temp folder if it exists\n",
    "    # if os.path.exists(os.path.join(os.getcwd(),'temp/')):\n",
    "    #     shutil.rmtree(os.path.join(os.getcwd(),'temp/'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf10d86e9ae7e3727a74de00a89e752a3f20ea127cee3e862a4392b6990960f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
